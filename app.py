# app.py

import streamlit as st
import torch
import os
import json
import numpy as np
import yaml
import pandas as pd
import time
from typing import List, Dict, Any

# Import components
from components.analyzer import get_sentiment_analyzer, analyze_with_gnn, analyze_multiple_reviews
from components.visualization import display_analysis_results, display_text_processing, display_summary_results
from components.crawler import show_crawler_section
from components.statistics import show_statistics_section
from components.data_processor import preprocess_text, create_node_features, get_text_preprocessor

# Import configs
from config.constants import (
    ASPECT_KEYWORDS_PATH, 
    EMOTION_WORDS_PATH, 
    CLASS_MAPPING, 
    CLASS_COLORS,
    AVAILABLE_MODELS,
    MODELS_DIR,
    MODEL_INFO
)

# Thi·∫øt l·∫≠p ti√™u ƒë·ªÅ v√† ch·∫ø ƒë·ªô layout
st.set_page_config(
    page_title="Ph√¢n t√≠ch c·∫£m x√∫c review kh√°ch s·∫°n",
    page_icon="üè®",
    layout="wide"
)

# H√†m main ƒë·ªÉ hi·ªÉn th·ªã giao di·ªán ·ª©ng d·ª•ng
def main():
    st.title("üè® Ph√¢n t√≠ch c·∫£m x√∫c review kh√°ch s·∫°n v·ªõi GNN")
    
    # T·∫°o tabs cho c√°c ch·ª©c nƒÉng kh√°c nhau
    tab1, tab2, tab3 = st.tabs(["Ph√¢n t√≠ch Review", "Thu th·∫≠p d·ªØ li·ªáu", "Th·ªëng k√™ & B√°o c√°o"])
    
    with tab1:
        # Sidebar cho vi·ªác ch·ªçn model v√† hi·ªÉn th·ªã th√¥ng tin
        st.sidebar.header("C√†i ƒë·∫∑t")
        
        # Hi·ªÉn th·ªã t√™n model theo ƒë·ªãnh d·∫°ng ƒë∆°n gi·∫£n
        model_display_name = lambda x: x.replace("best_", "").replace("_embedding.pt", "").replace(".pt", "")
        
        selected_model = st.sidebar.selectbox(
            "Ch·ªçn m√¥ h√¨nh GNN",
            AVAILABLE_MODELS,
            format_func=model_display_name
        )
        
        # X√°c ƒë·ªãnh lo·∫°i embedding t·ª´ t√™n model
        if "phobert" in selected_model:
            embedding_type = "phobert_embedding"
        elif "word2vec" in selected_model:
            embedding_type = "word2vec_embedding"
        elif "tfidf" in selected_model:
            embedding_type = "tfidf_embedding"
        else:
            st.sidebar.warning(f"Kh√¥ng th·ªÉ x√°c ƒë·ªãnh lo·∫°i embedding t·ª´ t√™n model: {selected_model}")
            st.sidebar.info("ƒêang s·ª≠ d·ª•ng lo·∫°i embedding m·∫∑c ƒë·ªãnh: phobert_embedding")
            embedding_type = "phobert_embedding"
        
        # X√°c ƒë·ªãnh lo·∫°i model
        if "gcn" in selected_model:
            model_type = "gcn"
        elif "gat" in selected_model:
            model_type = "gat"
        elif "sage" in selected_model:
            model_type = "sage"
        else:
            model_type = "unknownmodel"
        
        st.sidebar.markdown(f"**Lo·∫°i m√¥ h√¨nh:** {model_type.upper()}")
        st.sidebar.markdown(f"**Lo·∫°i embedding:** {embedding_type}")
        
        # Hi·ªÉn th·ªã th√¥ng tin v·ªÅ model
        # model_key = f"{model_type}_{embedding_type}"
        # if model_key in MODEL_INFO:
        #     st.sidebar.markdown("### Th√¥ng tin model")
        #     st.sidebar.markdown(f"**Accuracy:** {MODEL_INFO[model_key]['accuracy']:.3f}")
        #     st.sidebar.markdown(f"**F1 Score:** {MODEL_INFO[model_key]['f1']:.3f}")
        #     st.sidebar.markdown(f"**Training Time:** {MODEL_INFO[model_key]['time']}")
        
        # Hi·ªÉn th·ªã th√¥ng tin v·ªÅ qu√° tr√¨nh ph√¢n t√≠ch
        st.sidebar.markdown("### Th√¥ng tin qu√° tr√¨nh ph√¢n t√≠ch")
        show_processing = st.sidebar.checkbox("Hi·ªÉn th·ªã qu√° tr√¨nh x·ª≠ l√Ω vƒÉn b·∫£n", value=False)
        
        # H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng
        # with st.sidebar.expander("H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng"):
        #     st.markdown("""
        #     ### C√°ch s·ª≠ d·ª•ng
            
        #     1. **Ch·ªçn m√¥ h√¨nh GNN** ·ªü dropdown menu tr√™n sidebar
            
        #     2. **Ch·ªçn ch·∫ø ƒë·ªô nh·∫≠p reviews**:
        #        - *Nh·∫≠p m·ªôt review*: Ph√¢n t√≠ch m·ªôt review duy nh·∫•t
        #        - *Nh·∫≠p nhi·ªÅu reviews*: Ph√¢n t√≠ch h√†ng lo·∫°t reviews
            
        #     3. **Khi ph√¢n t√≠ch nhi·ªÅu reviews**:
        #        - Nh·∫≠p m·ªói review tr√™n m·ªôt d√≤ng, ho·∫∑c
        #        - T·∫£i l√™n file CSV ch·ª©a reviews (b·∫°n c√≥ th·ªÉ t·∫£i v·ªÅ template)
               
        #     4. **Nh·∫•n n√∫t "Ph√¢n t√≠ch"** ƒë·ªÉ xem k·∫øt qu·∫£
            
        #     5. **Xem k·∫øt qu·∫£ ph√¢n t√≠ch**:
        #        - T·ªïng quan ph√¢n ph·ªëi c·∫£m x√∫c
        #        - B·∫£ng chi ti·∫øt k·∫øt qu·∫£
        #        - C√°c kh√≠a c·∫°nh ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p nhi·ªÅu nh·∫•t
        #        - Chi ti·∫øt t·ª´ng review
        #     """)
        
        # Gi·∫£i th√≠ch v·ªÅ √Ω nghƒ©a c·∫£m x√∫c
        # with st.sidebar.expander("√ù nghƒ©a ƒëi·ªÉm c·∫£m x√∫c"):
        #     st.markdown("""
        #     ### √ù nghƒ©a ƒëi·ªÉm c·∫£m x√∫c
            
        #     - **0.0 - 0.4**: Ti√™u c·ª±c üî¥
        #     - **0.4 - 0.7**: Trung b√¨nh üü†
        #     - **0.7 - 1.0**: T√≠ch c·ª±c üü¢
            
        #     ƒêi·ªÉm c·∫£m x√∫c ƒë∆∞·ª£c t√≠nh d·ª±a tr√™n:
        #     - Ph√¢n t√≠ch t·ª´ kh√≥a t√≠ch c·ª±c/ti√™u c·ª±c trong review
        #     - T·ªïng h·ª£p c√°c kh√≠a c·∫°nh ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p
        #     - C∆∞·ªùng ƒë·ªô c·∫£m x√∫c th·ªÉ hi·ªán trong review
        #     """)
        
        # Ch·ªçn ch·∫ø ƒë·ªô nh·∫≠p review
        input_mode = st.radio(
            "Ch·∫ø ƒë·ªô nh·∫≠p review",
            ["Nh·∫≠p m·ªôt review", "Nh·∫≠p nhi·ªÅu reviews"]
        )
        
        if input_mode == "Nh·∫≠p m·ªôt review":
            # Ph·∫ßn nh·∫≠p vƒÉn b·∫£n ƒë∆°n
            st.subheader("üìù Nh·∫≠p review kh√°ch s·∫°n c·∫ßn ph√¢n t√≠ch")
            review_text = st.text_area("Nh·∫≠p n·ªôi dung review:", height=150)
            
            # N√∫t ph√¢n t√≠ch
            if st.button("üîç Ph√¢n t√≠ch review"):
                if not review_text:
                    st.warning("Vui l√≤ng nh·∫≠p n·ªôi dung review!")
                else:
                    with st.spinner("ƒêang x·ª≠ l√Ω v√† ph√¢n t√≠ch..."):
                        # Ph√¢n t√≠ch v·ªõi model ƒë√£ ch·ªçn
                        predicted_class, aspect_results, processed_text, overall_score, conclusions = analyze_with_gnn(
                            review_text, 
                            os.path.join(MODELS_DIR, selected_model),
                            embedding_type
                        )
                        
                        # Hi·ªÉn th·ªã k·∫øt qu·∫£ n·∫øu c√≥
                        if predicted_class is not None:
                             # Hi·ªÉn th·ªã qu√° tr√¨nh x·ª≠ l√Ω vƒÉn b·∫£n n·∫øu ƒë∆∞·ª£c ch·ªçn
                            if show_processing:
                                display_text_processing(processed_text)
                            # Hi·ªÉn th·ªã th√¥ng tin v·ªÅ model
                            st.markdown("### K·∫øt qu·∫£ ph√¢n t√≠ch")
                            
                            # X√°c ƒë·ªãnh model_type v√† embedding_type t·ª´ selected_model
                            model_type = "GCN" if "gcn" in selected_model else "GAT" if "gat" in selected_model else "GraphSAGE" if "sage" in selected_model else "Unknown"
                            embedding_name = "PhoBERT" if "phobert" in selected_model else "Word2Vec" if "word2vec" in selected_model else "TF-IDF" if "tfidf" in selected_model else "Unknown"
                            
                            # Hi·ªÉn th·ªã th√¥ng tin model
                            st.info(f"K·∫øt qu·∫£ t·ª´ model **{model_type}** v·ªõi embedding **{embedding_name}**")
                            
                            # Hi·ªÉn th·ªã k·∫øt qu·∫£ ph√¢n t√≠ch
                            display_analysis_results(review_text, predicted_class, aspect_results, overall_score, conclusions)

                            
                            # # Hi·ªÉn th·ªã th√¥ng tin v·ªÅ embedding
                            # with st.expander("Th√¥ng tin k·ªπ thu·∫≠t v·ªÅ embedding"):
                            #     st.markdown(f"**Lo·∫°i embedding:** {embedding_type}")
                                
                            #     # M√¥ t·∫£ v·ªÅ ph∆∞∆°ng ph√°p embedding
                            #     if embedding_type == "phobert_embedding":
                            #         st.markdown("""
                            #         **PhoBERT Embedding:**
                            #         - S·ª≠ d·ª•ng m√¥ h√¨nh ng√¥n ng·ªØ PhoBERT ƒë∆∞·ª£c hu·∫•n luy·ªán ƒë·∫∑c bi·ªát cho ti·∫øng Vi·ªát
                            #         - T·∫°o vector ƒë·∫∑c tr∆∞ng c√≥ ƒë·ªô d√†i 768 chi·ªÅu
                            #         - T√≠nh to√°n trung b√¨nh c·ªßa c√°c token embedding t·ª´ l·ªõp cu·ªëi c√πng
                            #         - Ph√π h·ª£p ƒë·∫∑c bi·ªát cho ph√¢n t√≠ch ng·ªØ nghƒ©a ti·∫øng Vi·ªát
                            #        """)
                            #     elif embedding_type == "word2vec_embedding":
                            #         st.markdown("""
                            #         **Word2Vec Embedding:**
                            #         - S·ª≠ d·ª•ng ph∆∞∆°ng ph√°p t·∫°o vector t·ª´ d·ª±a tr√™n ng·ªØ c·∫£nh
                            #         - T·∫°o vector ƒë·∫∑c tr∆∞ng c√≥ ƒë·ªô d√†i 100 chi·ªÅu
                            #         - T√≠nh to√°n trung b√¨nh c·ªßa c√°c word vector trong vƒÉn b·∫£n
                            #         - Hi·ªáu qu·∫£ cho c√°c t√°c v·ª• ph√¢n t√≠ch c·∫•p t·ª´ v√† ph√¢n lo·∫°i vƒÉn b·∫£n
                            #         """)
                            #     elif embedding_type == "tfidf_embedding":
                            #         st.markdown("""
                            #         **TF-IDF Embedding:**
                            #         - S·ª≠ d·ª•ng ph∆∞∆°ng ph√°p t·∫ßn su·∫•t t·ª´ - ngh·ªãch ƒë·∫£o t·∫ßn su·∫•t vƒÉn b·∫£n
                            #         - T·∫°o vector ƒë·∫∑c tr∆∞ng c√≥ ƒë·ªô d√†i l√™n ƒë·∫øn 1000 chi·ªÅu
                            #         - Th·ªÉ hi·ªán ƒë·ªô quan tr·ªçng c·ªßa t·ª´ng t·ª´ trong vƒÉn b·∫£n
                            #         - Ph√π h·ª£p cho ph√¢n lo·∫°i vƒÉn b·∫£n v√† truy v·∫•n th√¥ng tin
                            #         """)
                        else:
                            st.error("Kh√¥ng th·ªÉ ph√¢n t√≠ch. Vui l√≤ng th·ª≠ l·∫°i!")
        else:
            # Ph·∫ßn nh·∫≠p nhi·ªÅu vƒÉn b·∫£n
            st.subheader("üìù Nh·∫≠p nhi·ªÅu reviews kh√°ch s·∫°n c·∫ßn ph√¢n t√≠ch")
            
            # Option 1: Nh·∫≠p text tr·ª±c ti·∫øp
            reviews_text = st.text_area(
                "Nh·∫≠p m·ªói review tr√™n m·ªôt d√≤ng:",
                height=200,
                placeholder="Review 1\nReview 2\nReview 3\n..."
            )
            
            # Option 2: T·∫£i l√™n file CSV v√† t·∫£i v·ªÅ template
            col1, col2 = st.columns([2, 1])
            with col1:
                upload_file = st.file_uploader("Ho·∫∑c t·∫£i l√™n file CSV ch·ª©a reviews:", type=['csv'])
                
            with col2:
                # T·∫°o CSV template ƒë·ªÉ download
                template_df = pd.DataFrame({
                    'review': ['Nh·∫≠p review c·ªßa b·∫°n t·∫°i ƒë√¢y...', 'Kh√°ch s·∫°n n√†y r·∫•t t·ªët, nh√¢n vi√™n th√¢n thi·ªán', 'Ph√≤ng b·∫©n, nh√¢n vi√™n kh√¥ng nhi·ªát t√¨nh'],
                    'hotel_id': ['1', '2', '3'],
                    'rating': ['5', '4', '2']
                })
                
                # Convert DataFrame to CSV
                csv = template_df.to_csv(index=False)
                
                # Add download button
                st.download_button(
                    label="üì• T·∫£i v·ªÅ CSV Template",
                    data=csv,
                    file_name="reviews_template.csv",
                    mime="text/csv",
                    help="T·∫£i v·ªÅ file m·∫´u CSV ƒë·ªÉ ƒëi·ªÅn reviews v√† t·∫£i l√™n"
                )
            
            # N√∫t ph√¢n t√≠ch
            analyze_button = st.button("üîç Ph√¢n t√≠ch t·∫•t c·∫£ reviews", key="analyze_button")
            
            if analyze_button:
                reviews_to_analyze = []
                
                # X·ª≠ l√Ω reviews t·ª´ text area
                if reviews_text:
                    reviews_to_analyze.extend([r.strip() for r in reviews_text.split('\n') if r.strip()])
                
                # X·ª≠ l√Ω reviews t·ª´ file CSV n·∫øu c√≥
                if upload_file is not None:
                    try:
                        df = pd.read_csv(upload_file)
                        # Hi·ªÉn th·ªã preview c·ªßa d·ªØ li·ªáu CSV
                        with st.expander("Xem tr∆∞·ªõc d·ªØ li·ªáu CSV ƒë√£ t·∫£i l√™n"):
                            st.dataframe(df.head(10), use_container_width=True)
                        
                        # T√¨m c·ªôt c√≥ reviews (c√≥ th·ªÉ l√† 'review', 'comment', 'text', etc.)
                        review_column = None
                        possible_columns = ['review', 'comment', 'text', 'content', 'description', 'feedback']
                        
                        for col in possible_columns:
                            if col in df.columns:
                                review_column = col
                                break
                        
                        # N·∫øu kh√¥ng t√¨m th·∫•y, cho ph√©p ng∆∞·ªùi d√πng ch·ªçn c·ªôt
                        if review_column is None and len(df.columns) > 0:
                            review_column = st.selectbox(
                                "Vui l√≤ng ch·ªçn c·ªôt ch·ª©a n·ªôi dung review:",
                                options=df.columns.tolist(),
                                key="column_selector"
                            )
                        
                        # T√¨m c·ªôt hotel_id n·∫øu c√≥
                        hotel_id_column = None
                        possible_hotel_columns = ['hotel_id', 'hotel', 'hotel_name', 'accommodation_id']
                        
                        for col in possible_hotel_columns:
                            if col in df.columns:
                                hotel_id_column = col
                                break
                        
                        # L∆∞u DataFrame ban ƒë·∫ßu v√†o session_state ƒë·ªÉ c√≥ th·ªÉ l·ªçc m√† kh√¥ng ph·∫£i t·∫£i l·∫°i
                        if 'full_df' not in st.session_state:
                            st.session_state.full_df = df.copy()
                        
                        # N·∫øu c√≥ c·ªôt hotel_id, cho ph√©p ng∆∞·ªùi d√πng ch·ªçn hotel c·ª• th·ªÉ
                        if hotel_id_column:
                            # L·∫•y danh s√°ch c√°c hotel_id duy nh·∫•t
                            unique_hotels = sorted(st.session_state.full_df[hotel_id_column].dropna().unique().tolist())
                            
                            # Th√™m t√πy ch·ªçn "T·∫•t c·∫£ c√°c kh√°ch s·∫°n"
                            hotel_options = ["T·∫•t c·∫£ c√°c kh√°ch s·∫°n"] + unique_hotels
                            
                            # Kh·ªüi t·∫°o session_state cho hotel_selector n·∫øu ch∆∞a c√≥
                            if 'hotel_selection' not in st.session_state:
                                st.session_state.hotel_selection = "T·∫•t c·∫£ c√°c kh√°ch s·∫°n"
                            
                            # H√†m x·ª≠ l√Ω khi thay ƒë·ªïi kh√°ch s·∫°n
                            def update_hotel_selection():
                                st.session_state.hotel_selection = st.session_state.hotel_selector
                            
                            # Hi·ªÉn th·ªã dropdown ch·ªçn kh√°ch s·∫°n
                            selected_hotel = st.selectbox(
                                f"Ch·ªçn kh√°ch s·∫°n ƒë·ªÉ ph√¢n t√≠ch (t·ª´ c·ªôt {hotel_id_column}):",
                                options=hotel_options,
                                index=hotel_options.index(st.session_state.hotel_selection),
                                key="hotel_selector",
                                on_change=update_hotel_selection
                            )
                            
                            # L·ªçc DataFrame theo kh√°ch s·∫°n ƒë√£ ch·ªçn
                            if st.session_state.hotel_selection != "T·∫•t c·∫£ c√°c kh√°ch s·∫°n":
                                filtered_df = st.session_state.full_df[
                                    st.session_state.full_df[hotel_id_column] == st.session_state.hotel_selection
                                ]
                                df = filtered_df
                                st.info(f"ƒêang ph√¢n t√≠ch reviews cho kh√°ch s·∫°n: {st.session_state.hotel_selection}")
                                st.write(f"S·ªë l∆∞·ª£ng reviews: {len(filtered_df)}")
                            else:
                                df = st.session_state.full_df
                        
                        if review_column:
                            csv_reviews = df[review_column].dropna().tolist()
                            reviews_to_analyze.extend([str(r).strip() for r in csv_reviews if str(r).strip()])
                            st.success(f"ƒê√£ t·∫£i {len(csv_reviews)} reviews t·ª´ c·ªôt '{review_column}' c·ªßa file CSV.")
                        else:
                            st.error("Kh√¥ng t√¨m ƒë∆∞·ª£c c·ªôt ch·ª©a reviews trong file CSV.")
                    except Exception as e:
                        st.error(f"L·ªói khi ƒë·ªçc file CSV: {str(e)}")
                
                # Ki·ªÉm tra s·ªë l∆∞·ª£ng reviews
                if not reviews_to_analyze:
                    st.warning("Kh√¥ng c√≥ reviews n√†o ƒë·ªÉ ph√¢n t√≠ch. Vui l√≤ng nh·∫≠p n·ªôi dung review ho·∫∑c t·∫£i l√™n file CSV.")
                else:
                    # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng reviews ƒë·ªÉ tr√°nh qu√° t·∫£i
                    if len(reviews_to_analyze) > 100:
                        st.warning(f"C√≥ qu√° nhi·ªÅu reviews ({len(reviews_to_analyze)}). Ch·ªâ ph√¢n t√≠ch 100 reviews ƒë·∫ßu ti√™n.")
                        reviews_to_analyze = reviews_to_analyze[:100]
                    
                    # Ph√¢n t√≠ch t·∫•t c·∫£ reviews
                    analysis_results = analyze_multiple_reviews(
                        reviews_to_analyze,
                        os.path.join(MODELS_DIR, selected_model),
                        embedding_type
                    )
                    
                    # Hi·ªÉn th·ªã k·∫øt qu·∫£ t·ªïng h·ª£p
                    if analysis_results:
                        st.success(f"ƒê√£ ph√¢n t√≠ch th√†nh c√¥ng {len(analysis_results)} reviews!")
                        display_summary_results(analysis_results)
                        
                        # Hi·ªÉn th·ªã chi ti·∫øt t·ª´ng review
                        st.subheader("Chi ti·∫øt t·ª´ng review")
                        for i, result in enumerate(analysis_results):
                            with st.expander(f"Review #{result['id']}: {result['review'][:100]}{'...' if len(result['review']) > 100 else ''}"):
                                st.markdown(f"**Review ƒë·∫ßy ƒë·ªß:**")
                                st.text(result['review'])
                                st.markdown("---")
                                
                                # Hi·ªÉn th·ªã k·∫øt qu·∫£ ph√¢n t√≠ch cho review n√†y
                                display_analysis_results(
                                    result['review'], 
                                    result['predicted_class'], 
                                    result['aspect_results'],
                                    result['overall_score'],
                                    result['conclusions'],
                                    key_suffix=f"_{i}"
                                )
                                
                                # Hi·ªÉn th·ªã qu√° tr√¨nh x·ª≠ l√Ω vƒÉn b·∫£n n·∫øu ƒë∆∞·ª£c ch·ªçn
                                if show_processing:
                                    st.markdown("#### Th√¥ng tin x·ª≠ l√Ω vƒÉn b·∫£n")
                                    st.text_area(
                                        "VƒÉn b·∫£n sau khi x·ª≠ l√Ω:",
                                        result['processed_text']['final'],
                                        height=100,
                                        disabled=True,
                                        key=f"processed_text_{i}"
                                    )
                    else:
                        st.error("Kh√¥ng th·ªÉ ph√¢n t√≠ch c√°c reviews. Vui l√≤ng th·ª≠ l·∫°i!")
    
    # Tab 2: Thu th·∫≠p d·ªØ li·ªáu
    with tab2:
        show_crawler_section()
    
    # Tab 3: Th·ªëng k√™ & B√°o c√°o
    with tab3:
        show_statistics_section()

if __name__ == "__main__":
    main()