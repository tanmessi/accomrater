# ğŸ“„ Wiki: Quy trÃ¬nh PhÃ¡t triá»ƒn AccomRater ğŸ¨

## ğŸ“‘ Má»¥c lá»¥c

1. [Tá»•ng quan dá»± Ã¡n](#tá»•ng-quan-dá»±-Ã¡n)
2. [Thu tháº­p dá»¯ liá»‡u](#thu-tháº­p-dá»¯-liá»‡u)
3. [Tiá»n xá»­ lÃ½ dá»¯ liá»‡u](#tiá»n-xá»­-lÃ½-dá»¯-liá»‡u)
4. [XÃ¢y dá»±ng Ä‘á»“ thá»‹](#xÃ¢y-dá»±ng-Ä‘á»“-thá»‹)
5. [MÃ´ hÃ¬nh GNN](#mÃ´-hÃ¬nh-gnn)
6. [PhÃ¢n tÃ­ch sentiment](#phÃ¢n-tÃ­ch-sentiment)
7. [Há»‡ thá»‘ng gá»£i Ã½](#há»‡-thá»‘ng-gá»£i-Ã½)
8. [Triá»ƒn khai á»©ng dá»¥ng](#triá»ƒn-khai-á»©ng-dá»¥ng)

## ğŸ¯ Tá»•ng quan dá»± Ã¡n

AccomRater: Há»‡ thá»‘ng phÃ¢n tÃ­ch vÃ  gá»£i Ã½ cáº£i thiá»‡n dá»‹ch vá»¥ lÆ°u trÃº.

âœ… Má»¥c tiÃªu:
â†³ Thu tháº­p Ä‘Ã¡nh giÃ¡ tá»« Booking.com vÃ  Agoda.com
â†³ PhÃ¢n tÃ­ch cáº£m xÃºc theo khÃ­a cáº¡nh dá»‹ch vá»¥
â†³ XÃ¢y dá»±ng mÃ´ hÃ¬nh GNN cho phÃ¢n tÃ­ch káº¿t ná»‘i
â†³ Gá»£i Ã½ cáº£i thiá»‡n dá»‹ch vá»¥ dá»±a trÃªn phÃ¢n tÃ­ch

ğŸ“¦ PhiÃªn báº£n: v1.0.0

## ğŸ•¸ï¸ Thu tháº­p dá»¯ liá»‡u

### ğŸ”„ Crawling tá»« Booking.com

```bash
python run_booking_crawler.py
```

âœ… Thá»±c hiá»‡n:
â†³ Khá»Ÿi táº¡o BookingCrawler vá»›i tham sá»‘ tá»« .env
â†³ Má»Ÿ trang tÃ¬m kiáº¿m khÃ¡ch sáº¡n vá»›i Selenium
â†³ Scroll trang Ä‘á»ƒ táº£i thÃªm káº¿t quáº£
â†³ Thu tháº­p URLs cá»§a cÃ¡c khÃ¡ch sáº¡n
â†³ Truy cáº­p tá»«ng URL Ä‘á»ƒ láº¥y thÃ´ng tin chi tiáº¿t
â†³ Lá»c vÃ  thu tháº­p Ä‘Ã¡nh giÃ¡ tiáº¿ng Viá»‡t

âš™ï¸ Tham sá»‘ cáº¥u hÃ¬nh:
```
HEADLESS_MODE=true
CRAWL_DELAY=3
MAX_HOTELS=100
MAX_REVIEWS_PER_HOTEL=300
```

### ğŸ”„ Crawling tá»« Agoda.com

```bash
python run_agoda_crawler.py
```

âœ… Thá»±c hiá»‡n:
â†³ Sá»­ dá»¥ng GraphQL API hoáº·c Selenium tÃ¹y theo cáº¥u hÃ¬nh
â†³ Thu tháº­p thÃ´ng tin cÆ¡ báº£n cá»§a khÃ¡ch sáº¡n
â†³ Truy cáº­p trang chi tiáº¿t Ä‘á»ƒ láº¥y thÃ´ng tin vÃ  Ä‘Ã¡nh giÃ¡
â†³ Táº¡o hash cho má»—i Ä‘Ã¡nh giÃ¡ Ä‘á»ƒ trÃ¡nh trÃ¹ng láº·p

âš ï¸ LÆ°u Ã½:
â†’ Kiá»ƒm tra selectors thÆ°á»ng xuyÃªn vÃ¬ website thay Ä‘á»•i
â†’ Thiáº¿t láº­p CRAWL_DELAY Ä‘á»§ lá»›n Ä‘á»ƒ trÃ¡nh bá»‹ cháº·n
â†’ Sá»­ dá»¥ng proxy rotation náº¿u cáº§n thu tháº­p dá»¯ liá»‡u lá»›n

### ğŸ’¾ LÆ°u trá»¯ dá»¯ liá»‡u

âœ… Cáº¥u trÃºc DB:
â†³ PostgreSQL vá»›i schema Ä‘Ã£ Ä‘á»‹nh nghÄ©a
â†³ 4 báº£ng chÃ­nh: hotels, reviews, hotel_ratings, sentiment_analysis

ğŸ”„ Quy trÃ¬nh:
```python
# LÆ°u thÃ´ng tin khÃ¡ch sáº¡n
hotel = Hotel.create(
    name=hotel_data['name'],
    address=hotel_data['address'],
    rating=rating,
    source="Booking.com",
    hotel_url=url
)

# LÆ°u Ä‘Ã¡nh giÃ¡
for review in reviews_data:
    Review.create(
        hotel_id=hotel.id,
        rating=review_rating,
        comment=review.get('comment', ''),
        review_date=review_date_obj,
        source="Booking.com",
        reviewer_name=review.get('reviewer_name'),
        reviewer_hash=review.get('reviewer_hash')
    )
```

ğŸ“ Vá»‹ trÃ­: /crawlers/booking_crawler.py, /crawlers/agoda_crawler.py

## ğŸ§¹ Tiá»n xá»­ lÃ½ dá»¯ liá»‡u

### ğŸ”„ LÃ m sáº¡ch vÄƒn báº£n

```python
class TextPreprocessor:
    def preprocess_pipeline(self, text):
        # Cleaning
        text = self.clean_text(text)
        # Vietnamese processing
        text = self.correct_spelling(text)
        text = self.handle_teencode(text)
        text = self.segment_text(text)
        return text
```

âœ… Thá»±c hiá»‡n:
â†³ Loáº¡i bá» HTML tags
â†³ Xá»­ lÃ½ emoji (thay tháº¿ hoáº·c loáº¡i bá»)
â†³ Loáº¡i bá» URL
â†³ Chuáº©n hÃ³a whitespace

ğŸ“ Vá»‹ trÃ­: /data_preprocessing/preprocessing.py

### ğŸ‡»ğŸ‡³ Xá»­ lÃ½ tiáº¿ng Viá»‡t

âœ… Thá»±c hiá»‡n:
â†³ Sá»­a lá»—i chÃ­nh táº£ vá»›i SymSpellPy
â†³ Xá»­ lÃ½ tá»« Ä‘á»‹a phÆ°Æ¡ng (mapping tá»« Ä‘iá»ƒn)
â†³ Xá»­ lÃ½ teencode ("k" â†’ "khÃ´ng", "vk" â†’ "vá»£")
â†³ TÃ¡ch tá»« (word segmentation) vá»›i PyVi

```python
# VÃ­ dá»¥: Xá»­ lÃ½ teencode vÃ  tá»« Ä‘á»‹a phÆ°Æ¡ng
class VietnameseLocalDictionary:
    def normalize_text(self, text):
        words = text.split()
        for i, word in enumerate(words):
            if word in self.local_dict:
                words[i] = self.local_dict[word]
            elif word in self.teencode_dict:
                words[i] = self.teencode_dict[word]
        return ' '.join(words)
```

ğŸ“ Vá»‹ trÃ­: /data_preprocessing/vietnamese_utils/

### ğŸ“Š TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng

âœ… Thá»±c hiá»‡n:
â†³ TF-IDF Vectorization
â†³ Word Embeddings vá»›i Word2Vec hoáº·c FastText
â†³ PhoBERT Embeddings Ä‘áº·c biá»‡t cho tiáº¿ng Viá»‡t

```python
def get_document_embedding(self, text):
    if self.model_type == 'phobert':
        inputs = self.tokenizer(text, return_tensors="pt", padding=True, truncation=True)
        with torch.no_grad():
            outputs = self.model(**inputs)
        embeddings = torch.mean(outputs.last_hidden_state, dim=1)
        return embeddings.numpy()
```

ğŸ“ Vá»‹ trÃ­: /data_preprocessing/vectorization/

## ğŸ•¸ï¸ XÃ¢y dá»±ng Ä‘á»“ thá»‹

### ğŸ”„ Táº¡o Ä‘á»“ thá»‹ tá»« dá»¯ liá»‡u quan há»‡

âœ… Loáº¡i Ä‘á»‰nh (node):
â†³ KhÃ¡ch sáº¡n (hotel nodes)
â†³ NgÆ°á»i dÃ¹ng (user nodes)
â†³ ÄÃ¡nh giÃ¡ (review nodes)
â†³ KhÃ­a cáº¡nh dá»‹ch vá»¥ (aspect nodes)

âœ… Loáº¡i cáº¡nh (edge):
â†³ User-Review: NgÆ°á»i dÃ¹ng viáº¿t Ä‘Ã¡nh giÃ¡
â†³ Review-Hotel: ÄÃ¡nh giÃ¡ thuá»™c khÃ¡ch sáº¡n
â†³ Review-Aspect: ÄÃ¡nh giÃ¡ Ä‘á» cáº­p Ä‘áº¿n khÃ­a cáº¡nh
â†³ Hotel-Aspect: KhÃ¡ch sáº¡n cÃ³ khÃ­a cáº¡nh dá»‹ch vá»¥

```python
def build_graph(self):
    G = nx.Graph()
    
    # ThÃªm hotel nodes
    for hotel in self.hotels:
        G.add_node(f"hotel_{hotel.id}", type='hotel', data=hotel)
    
    # ThÃªm review nodes vÃ  káº¿t ná»‘i
    for review in self.reviews:
        G.add_node(f"review_{review.id}", type='review', data=review)
        G.add_edge(f"review_{review.id}", f"hotel_{review.hotel_id}")
        
        # Náº¿u cÃ³ reviewer_hash, thÃªm user node
        if review.reviewer_hash:
            G.add_node(f"user_{review.reviewer_hash}", type='user')
            G.add_edge(f"user_{review.reviewer_hash}", f"review_{review.id}")
            
    # ThÃªm aspect nodes vÃ  káº¿t ná»‘i
    for sentiment in self.sentiments:
        G.add_node(f"aspect_{sentiment.aspect}", type='aspect')
        G.add_edge(f"review_{sentiment.review_id}", f"aspect_{sentiment.aspect}", 
                  weight=sentiment.weight, score=sentiment.sentiment_score)
    
    return G
```

ğŸ“ Vá»‹ trÃ­: /model_training/graph/graph_builder.py

### ğŸ§® TÃ­nh toÃ¡n Ä‘áº·c trÆ°ng cho Ä‘á»“ thá»‹

âœ… Äáº·c trÆ°ng node:
â†³ Hotel nodes: rating, sá»‘ lÆ°á»£ng review, vá»‹ trÃ­ Ä‘á»‹a lÃ½
â†³ Review nodes: rating, Ä‘á»™ dÃ i review, sentiment score
â†³ User nodes: sá»‘ lÆ°á»£ng review, thá»i gian hoáº¡t Ä‘á»™ng
â†³ Aspect nodes: one-hot encoding cho tá»«ng khÃ­a cáº¡nh

âœ… Äáº·c trÆ°ng edge:
â†³ Äá»™ máº¡nh cá»§a sentiment (weight)
â†³ Sentiment score
â†³ Thá»i gian (temporal features)

ğŸ“ Vá»‹ trÃ­: /model_training/graph/feature_extraction.py

## ğŸ§  MÃ´ hÃ¬nh GNN

### ğŸ“ Kiáº¿n trÃºc mÃ´ hÃ¬nh

âœ… MÃ´ hÃ¬nh GCN:
```python
class GCNModel(torch.nn.Module):
    def __init__(self, in_channels, hidden_channels, out_channels):
        super(GCNModel, self).__init__()
        self.conv1 = GCNConv(in_channels, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, hidden_channels)
        self.conv3 = GCNConv(hidden_channels, out_channels)
        
    def forward(self, x, edge_index, edge_weight=None):
        x = self.conv1(x, edge_index, edge_weight)
        x = F.relu(x)
        x = F.dropout(x, training=self.training)
        x = self.conv2(x, edge_index, edge_weight)
        x = F.relu(x)
        x = self.conv3(x, edge_index, edge_weight)
        return x
```

âœ… MÃ´ hÃ¬nh GAT:
```python
class GATModel(torch.nn.Module):
    def __init__(self, in_channels, hidden_channels, out_channels, heads=4):
        super(GATModel, self).__init__()
        self.conv1 = GATConv(in_channels, hidden_channels, heads)
        self.conv2 = GATConv(hidden_channels * heads, out_channels)
        
    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = F.elu(x)
        x = F.dropout(x, training=self.training)
        x = self.conv2(x, edge_index)
        return x
```

ğŸ“ Vá»‹ trÃ­: /model_training/graph/models.py

### ğŸ”„ Huáº¥n luyá»‡n mÃ´ hÃ¬nh

âœ… Thiáº¿t láº­p:
â†³ Batch size: 32
â†³ Learning rate: 0.001
â†³ Epochs: 100
â†³ Loss function: Cross Entropy (phÃ¢n loáº¡i) hoáº·c MSE (regression)
â†³ Optimizer: Adam

```python
def train(self, model, data, optimizer):
    model.train()
    optimizer.zero_grad()
    # Forward pass
    out = model(data.x, data.edge_index, data.edge_attr)
    # Calculate loss
    loss = F.mse_loss(out[data.train_mask], data.y[data.train_mask])
    # Backward pass
    loss.backward()
    optimizer.step()
    return loss.item()
```

âš ï¸ LÆ°u Ã½:
â†’ Sá»­ dá»¥ng cross-validation Ä‘á»ƒ trÃ¡nh overfitting
â†’ LÆ°u mÃ´ hÃ¬nh tá»‘t nháº¥t dá»±a trÃªn val_loss
â†’ Kiá»ƒm soÃ¡t early stopping

ğŸ“ Vá»‹ trÃ­: /model_training/graph/train.py

## ğŸ’­ PhÃ¢n tÃ­ch sentiment

### ğŸ” TrÃ­ch xuáº¥t khÃ­a cáº¡nh dá»‹ch vá»¥

âœ… KhÃ­a cáº¡nh chÃ­nh:
â†³ PhÃ²ng (room): sáº¡ch sáº½, tiá»‡n nghi, rá»™ng rÃ£i...
â†³ NhÃ¢n viÃªn (staff): thÃ¢n thiá»‡n, chuyÃªn nghiá»‡p...
â†³ Dá»‹ch vá»¥ (service): cháº¥t lÆ°á»£ng, Ä‘a dáº¡ng...
â†³ Vá»‹ trÃ­ (location): gáº§n trung tÃ¢m, an ninh...
â†³ GiÃ¡ cáº£ (price): há»£p lÃ½, Ä‘áº¯t, ráº»...
â†³ áº¨m thá»±c (food): ngon, Ä‘a dáº¡ng, phong phÃº...

âœ… TrÃ­ch xuáº¥t khÃ­a cáº¡nh:
â†³ Sá»­ dá»¥ng mÃ´ hÃ¬nh GNN Ä‘á»ƒ phÃ¢n loáº¡i text fragments
â†³ Káº¿t há»£p vá»›i lexicon-based approach
â†³ Ãp dá»¥ng dependency parsing Ä‘á»ƒ xÃ¡c Ä‘á»‹nh quan há»‡

### ğŸ”„ PhÃ¢n tÃ­ch sentiment theo khÃ­a cáº¡nh

âœ… Quy trÃ¬nh:
â†³ TÃ¡ch comment thÃ nh cÃ¡c cá»¥m theo khÃ­a cáº¡nh
â†³ XÃ¡c Ä‘á»‹nh sentiment score cho má»—i cá»¥m (-1 Ä‘áº¿n 1)
â†³ GÃ¡n trá»ng sá»‘ cho má»—i khÃ­a cáº¡nh dá»±a trÃªn Ä‘á»™ dÃ i vÃ  vá»‹ trÃ­
â†³ Tá»•ng há»£p sentiment scores theo khÃ­a cáº¡nh

```python
def analyze_aspect_sentiment(self, review_text):
    aspects = {}
    # PhÃ¢n Ä‘oáº¡n vÄƒn báº£n theo khÃ­a cáº¡nh
    segments = self.aspect_segmenter.segment(review_text)
    
    for segment in segments:
        aspect = segment['aspect']
        text = segment['text']
        # PhÃ¢n tÃ­ch sentiment
        score = self.sentiment_analyzer.analyze(text)
        weight = len(text) / len(review_text)
        
        if aspect in aspects:
            aspects[aspect]['score'] += score * weight
            aspects[aspect]['weight'] += weight
        else:
            aspects[aspect] = {
                'score': score * weight,
                'weight': weight,
                'keywords': self.extract_keywords(text)
            }
    
    # Chuáº©n hÃ³a scores
    for aspect in aspects:
        aspects[aspect]['score'] /= aspects[aspect]['weight']
    
    return aspects
```

ğŸ“ Vá»‹ trÃ­: /sentiment_analysis/aspect_sentiment.py

## ğŸ’¡ Há»‡ thá»‘ng gá»£i Ã½

### ğŸ“Š PhÃ¢n tÃ­ch Ä‘iá»ƒm yáº¿u

âœ… Thá»±c hiá»‡n:
â†³ Tá»•ng há»£p sentiment scores theo khÃ­a cáº¡nh
â†³ XÃ¡c Ä‘á»‹nh khÃ­a cáº¡nh cÃ³ Ä‘iá»ƒm tháº¥p nháº¥t
â†³ So sÃ¡nh vá»›i benchmark cá»§a cÃ¡c khÃ¡ch sáº¡n tÆ°Æ¡ng tá»±
â†³ XÃ¡c Ä‘á»‹nh má»©c Ä‘á»™ Æ°u tiÃªn cáº£i thiá»‡n

```python
def identify_weaknesses(self, hotel_id):
    # Láº¥y sentiment scores theo khÃ­a cáº¡nh
    aspect_scores = self.get_aspect_scores(hotel_id)
    
    # So sÃ¡nh vá»›i benchmark
    benchmarks = self.get_benchmarks(hotel_id)
    
    weaknesses = []
    for aspect, score in aspect_scores.items():
        if score['avg_score'] < benchmarks[aspect]:
            gap = benchmarks[aspect] - score['avg_score']
            weaknesses.append({
                'aspect': aspect,
                'score': score['avg_score'],
                'benchmark': benchmarks[aspect],
                'gap': gap,
                'priority': self.calculate_priority(gap, aspect)
            })
    
    # Sáº¯p xáº¿p theo má»©c Ä‘á»™ Æ°u tiÃªn
    return sorted(weaknesses, key=lambda x: x['priority'], reverse=True)
```

ğŸ“ Vá»‹ trÃ­: /recommendation/weakness_analyzer.py

### ğŸš€ Äá» xuáº¥t cáº£i thiá»‡n

âœ… Thá»±c hiá»‡n:
â†³ PhÃ¢n tÃ­ch tá»« khÃ³a phá»• biáº¿n trong Ä‘Ã¡nh giÃ¡ tiÃªu cá»±c
â†³ TÃ¬m cÃ¡c pattern láº·p láº¡i trong cÃ¡c váº¥n Ä‘á»
â†³ Tá»•ng há»£p recommender knowledge base
â†³ Äá» xuáº¥t cÃ¡c hÃ nh Ä‘á»™ng cá»¥ thá»ƒ theo váº¥n Ä‘á»

```python
def generate_recommendations(self, hotel_id):
    # XÃ¡c Ä‘á»‹nh Ä‘iá»ƒm yáº¿u
    weaknesses = self.weakness_analyzer.identify_weaknesses(hotel_id)
    
    recommendations = []
    for weakness in weaknesses:
        aspect = weakness['aspect']
        # TrÃ­ch xuáº¥t tá»« khÃ³a tiÃªu cá»±c
        negative_keywords = self.get_negative_keywords(hotel_id, aspect)
        
        # TÃ¬m pattern phá»• biáº¿n
        patterns = self.identify_patterns(negative_keywords)
        
        # Táº¡o Ä‘á» xuáº¥t tá»« knowledge base
        aspect_recommendations = self.recommendation_knowledge.get_recommendations(
            aspect, patterns, weakness['score']
        )
        
        recommendations.append({
            'aspect': aspect,
            'score': weakness['score'],
            'gap': weakness['gap'],
            'keywords': negative_keywords,
            'recommendations': aspect_recommendations
        })
    
    return recommendations
```

âš™ï¸ VÃ­ dá»¥ Ä‘á» xuáº¥t:
- PhÃ²ng (3.2/5): 
  - Cáº£i thiá»‡n cÃ¡ch Ã¢m giá»¯a cÃ¡c phÃ²ng
  - NÃ¢ng cáº¥p há»‡ thá»‘ng Ä‘iá»u hÃ²a
  - Thay má»›i Ä‘á»“ váº£i giÆ°á»ng
- NhÃ¢n viÃªn (3.8/5):
  - Tá»• chá»©c training giao tiáº¿p tiáº¿ng Anh
  - Cáº£i thiá»‡n quy trÃ¬nh check-in/check-out

ğŸ“ Vá»‹ trÃ­: /recommendation/recommendation_generator.py

## ğŸš€ Triá»ƒn khai á»©ng dá»¥ng

### ğŸ“Š Dashboard vÃ  UI

âœ… Thá»±c hiá»‡n:
â†³ XÃ¢y dá»±ng dashboard vá»›i Streamlit
â†³ Hiá»ƒn thá»‹ trá»±c quan cÃ¡c phÃ¢n tÃ­ch sentiment
â†³ Cung cáº¥p cÃ¡c Ä‘á» xuáº¥t cáº£i thiá»‡n
â†³ TÃ­ch há»£p filter vÃ  tÃ¹y chá»‰nh

```python
def show():
    st.title("AccomRater - PhÃ¢n tÃ­ch vÃ  Äá» xuáº¥t")
    
    # Chá»n khÃ¡ch sáº¡n
    hotel_id = st.selectbox("Chá»n khÃ¡ch sáº¡n", options=get_hotel_list())
    
    if st.button("PhÃ¢n tÃ­ch"):
        # PhÃ¢n tÃ­ch sentiment
        sentiment_results = analyze_sentiment(hotel_id)
        
        # Hiá»ƒn thá»‹ biá»ƒu Ä‘á»“
        st.subheader("PhÃ¢n tÃ­ch sentiment theo khÃ­a cáº¡nh")
        display_sentiment_chart(sentiment_results)
        
        # Hiá»ƒn thá»‹ Ä‘á» xuáº¥t
        st.subheader("Äá» xuáº¥t cáº£i thiá»‡n")
        recommendations = generate_recommendations(hotel_id)
        display_recommendations(recommendations)
```

ğŸ“ Vá»‹ trÃ­: /ui/dashboard.py

### ğŸ”„ Cáº­p nháº­t dá»¯ liá»‡u tá»± Ä‘á»™ng

âœ… Thá»±c hiá»‡n:
â†³ Cron job cháº¡y crawler Ä‘á»‹nh ká»³ (hÃ ng tuáº§n)
â†³ Cáº­p nháº­t dá»¯ liá»‡u vÃ o database
â†³ TÃ¡i huáº¥n luyá»‡n mÃ´ hÃ¬nh vá»›i dá»¯ liá»‡u má»›i
â†³ Cáº­p nháº­t Ä‘á» xuáº¥t

```bash
# VÃ­ dá»¥ crontab
0 0 * * 0 cd /path/to/accomrater && python run_crawlers.py >> logs/cron.log 2>&1
0 2 * * 0 cd /path/to/accomrater && python retrain_models.py >> logs/cron.log 2>&1
```

âš ï¸ LÆ°u Ã½:
â†’ Xá»­ lÃ½ lá»—i vÃ  backup dá»¯ liá»‡u trÆ°á»›c má»—i láº§n cáº­p nháº­t
â†’ LÆ°u láº¡i metrics Ä‘á»ƒ theo dÃµi hiá»‡u suáº¥t mÃ´ hÃ¬nh theo thá»i gian
â†’ ThÃ´ng bÃ¡o khi phÃ¡t hiá»‡n thay Ä‘á»•i Ä‘Ã¡ng ká»ƒ trong data distribution

## ğŸ“¦ TÃ i liá»‡u tham kháº£o

- [Graph Neural Networks](https://distill.pub/2021/gnn-intro/)
- [Aspect-Based Sentiment Analysis](https://www.aclweb.org/anthology/S14-2004.pdf)
- [PhoBERT: Pre-trained language models for Vietnamese](https://arxiv.org/abs/2003.00744)
- [PyTorch Geometric Documentation](https://pytorch-geometric.readthedocs.io/)

---

**ğŸ”„ Tráº¡ng thÃ¡i:** ÄÃ£ hoÃ n thÃ nh version 1.0
**ğŸ“… Cáº­p nháº­t:** 04/03/2025